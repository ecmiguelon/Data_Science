{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secure Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game Specification \n",
    "\n",
    "According to [1] we can model a secure learning system as a game between an attacker and a defender - The attacker wants to manipualte or evade a learning algorithm choosen by the defender. \n",
    "\n",
    "1. __Defender__ Choose learning algorithm $H$ for selecting hypotheses based on observed data\n",
    "\n",
    "2. __Attacker__ Choose attack procedures $A^{(train)}$ and $A^{(eval)}$ (potentially with knowledge of $H$)\n",
    "\n",
    "3. Learning:\n",
    "    + Obtain dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-197aba586699>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-197aba586699>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Usuarios\\rhaps\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Usuarios\\rhaps\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Usuarios\\rhaps\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Usuarios\\rhaps\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../Machine_learning/Tensorflow/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Usuarios\\rhaps\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Usuarios\\rhaps\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../Machine_learning/Tensorflow/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Usuarios\\rhaps\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Usuarios\\rhaps\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../Machine_learning/Tensorflow/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../Machine_learning/Tensorflow/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Usuarios\\rhaps\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Usuarios\\rhaps\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Read data\n",
    "mnist = input_data.read_data_sets(\"../Machine_learning/Tensorflow/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Error: 0.18379998207092285\n",
      "Validation Error: 0.06440001726150513\n",
      "Validation Error: 0.04839998483657837\n",
      "Validation Error: 0.04119998216629028\n",
      "Validation Error: 0.03539997339248657\n",
      "Validation Error: 0.03280001878738403\n",
      "Validation Error: 0.028199970722198486\n",
      "Validation Error: 0.027199983596801758\n",
      "Validation Error: 0.0252000093460083\n",
      "Validation Error: 0.025799989700317383\n",
      "Validation Error: 0.02399998903274536\n",
      "Validation Error: 0.023599982261657715\n",
      "Validation Error: 0.022599995136260986\n",
      "Validation Error: 0.022599995136260986\n",
      "Validation Error: 0.02340000867843628\n",
      "Validation Error: 0.022599995136260986\n",
      "Validation Error: 0.021799981594085693\n",
      "Validation Error: 0.02240002155303955\n",
      "Validation Error: 0.02060002088546753\n",
      "Validation Error: 0.02120000123977661\n",
      "Validation Error: 0.02039998769760132\n",
      "Validation Error: 0.02060002088546753\n",
      "Validation Error: 0.02120000123977661\n",
      "Validation Error: 0.019599974155426025\n",
      "Validation Error: 0.020200014114379883\n",
      "Validation Error: 0.019800007343292236\n",
      "Validation Error: 0.021000027656555176\n",
      "Validation Error: 0.019599974155426025\n",
      "Validation Error: 0.019200026988983154\n",
      "Validation Error: 0.019200026988983154\n",
      "Validation Error: 0.01940000057220459\n",
      "Validation Error: 0.018800020217895508\n",
      "Validation Error: 0.019800007343292236\n",
      "Validation Error: 0.019800007343292236\n",
      "Validation Error: 0.020200014114379883\n",
      "Validation Error: 0.019599974155426025\n",
      "Validation Error: 0.01940000057220459\n",
      "Validation Error: 0.01940000057220459\n",
      "Validation Error: 0.01940000057220459\n",
      "Validation Error: 0.018800020217895508\n",
      "Validation Error: 0.019599974155426025\n",
      "Validation Error: 0.018800020217895508\n",
      "Validation Error: 0.01940000057220459\n",
      "Validation Error: 0.018800020217895508\n",
      "Validation Error: 0.019599974155426025\n",
      "Validation Error: 0.019599974155426025\n",
      "Validation Error: 0.019999980926513672\n",
      "Validation Error: 0.019599974155426025\n",
      "Validation Error: 0.019599974155426025\n",
      "Validation Error: 0.018800020217895508\n",
      "Validation Error: 0.01940000057220459\n",
      "Validation Error: 0.018999993801116943\n",
      "Validation Error: 0.019200026988983154\n",
      "Validation Error: 0.018800020217895508\n",
      "Validation Error: 0.019200026988983154\n",
      "Validation Error: 0.018599987030029297\n",
      "Validation Error: 0.018999993801116943\n",
      "Validation Error: 0.018800020217895508\n",
      "Validation Error: 0.019599974155426025\n",
      "Validation Error: 0.01940000057220459\n",
      "Optimization Finished!\n",
      "Test Accuracy: 0.9788\n",
      "Model saved in path: /tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "def layer(input, weigth_shape, bias_shape):\n",
    "    w_init = tf.random_normal_initializer(stddev= (2.0/weigth_shape[0]) ** 0.5)\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    W = tf.get_variable(\"W\", weigth_shape, initializer = w_init)\n",
    "    b = tf.get_variable(\"b\", bias_shape, initializer = bias_init)\n",
    "    return tf.nn.relu(tf.matmul(input, W) + b)\n",
    "\n",
    "def inference(x):     \n",
    "    with tf.variable_scope(\"hidden_1\"):\n",
    "        hidden_1 = layer(x , [784, 256], [256])\n",
    "    with tf.variable_scope(\"hidden_2\"):\n",
    "        hidden_2 = layer(hidden_1, [256, 256], [256])\n",
    "    with tf.variable_scope(\"output\"):\n",
    "        output = layer(hidden_2, [256, 10], [10])\n",
    "    return output\n",
    "\n",
    "def loss(output, y):\n",
    "    xentropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=output, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    return loss\n",
    "\n",
    "def evaluate(output, y):\n",
    "    correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"validation\", accuracy)\n",
    "    return accuracy\n",
    "\n",
    "def training(cost, global_step):\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_op\n",
    "\n",
    "import tensorflow as tf\n",
    "# Parameters\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_epochs = 300\n",
    "batch_size = 100\n",
    "display_step = 5\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    # mnist data image of shape 28*28=784\n",
    "    x = tf.placeholder(tf.float32, [None, 784])    \n",
    "    # 0-9 digits recognition => 10 classes\n",
    "    y = tf.placeholder(tf.float32, [None, 10])    \n",
    "    output = inference(x)    \n",
    "    cost = loss(output, y) \n",
    "    \n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)    \n",
    "    train_op = training(cost, global_step)    \n",
    "    eval_op = evaluate(output, y)\n",
    "    \n",
    "    summary_op = tf.summary.merge_all()    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    sess = tf.Session()    \n",
    "    summary_writer = tf.summary.FileWriter(\"mnist_logs/\", graph=sess.graph)\n",
    "    \n",
    "    init_op = tf.global_variables_initializer()    \n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            mbatch_x, mbatch_y = mnist.train.next_batch(batch_size)\n",
    "            # Fit training using batch data\n",
    "            feed_dict = {x : mbatch_x, y : mbatch_y}\n",
    "            sess.run(train_op, feed_dict=feed_dict)\n",
    "            # Compute average loss\n",
    "            minibatch_cost = sess.run(cost, feed_dict=feed_dict)\n",
    "            avg_cost += minibatch_cost/total_batch\n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            val_feed_dict = {\n",
    "                x : mnist.validation.images,\n",
    "                y : mnist.validation.labels\n",
    "            }\n",
    "            accuracy = sess.run(eval_op, feed_dict=val_feed_dict)\n",
    "            print (\"Validation Error:\", (1 - accuracy))\n",
    "            train_losses.append(1 - accuracy)\n",
    "            summary_str = sess.run(summary_op, feed_dict=feed_dict)\n",
    "            summary_writer.add_summary(summary_str, sess.run(global_step))\n",
    "            \n",
    "            saver.save(sess, \"mnist_logs/model-checkpoint\", global_step=global_step)\n",
    "            \n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "    test_feed_dict = {\n",
    "        x : mnist.test.images,\n",
    "        y : mnist.test.labels\n",
    "    }\n",
    "    accuracy = sess.run(eval_op, feed_dict=test_feed_dict)\n",
    "    #writer = tf.summary.FileWriter(\"logistic_logs3/\", graph=sess.graph)\n",
    "    #writer.add_graph(tf.get_default_graph())\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "    \n",
    "    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test model versus adversial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 432, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "img=cv2.imread('output/fig3.png')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Usuarios\\rhaps\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from scipy import ndimage, misc\n",
    "ok = misc.imresize(img,(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 373248 into shape (28,28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-3de6744967a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gray_r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 373248 into shape (28,28)"
     ]
    }
   ],
   "source": [
    "plt.imshow(img.reshape(28,28), cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-3a66bb58f126>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Queremos las imágenes en grises\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mok\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Imprimir una imagen dada\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mmatshow\u001b[1;34m(A, fignum, **kw)\u001b[0m\n\u001b[0;32m   2422\u001b[0m         \u001b[0max\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_axes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.09\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.775\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.775\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2424\u001b[1;33m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2425\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mmatshow\u001b[1;34m(self, Z, **kwargs)\u001b[0m\n\u001b[0;32m   7720\u001b[0m         \"\"\"\n\u001b[0;32m   7721\u001b[0m         \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7722\u001b[1;33m         \u001b[0mnr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7723\u001b[0m         kw = {'origin': 'upper',\n\u001b[0;32m   7724\u001b[0m               \u001b[1;34m'interpolation'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'nearest'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQwAAAECCAYAAAALhunjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADNJJREFUeJzt23+o3fV9x/HnS7OszFk76i2UJNaUxdlMBrqLOAqrpW5EB8k/riQgmyMY2tXuj5aBw+GK/WuWrVDI1gUmtoVq0/6xXkok0E6xSGO9orUmknGXunlJmWlr/Uf8xd7745x1x+tN7jvXc+85t3s+IHC+3/O53/v2cPP0+/3eb1JVSFLHBZMeQNLGYTAktRkMSW0GQ1KbwZDUZjAkta0YjCT3JnkhyTNneT9JvpBkIcnTSa4Z/5iSpkHnDOM+YNc53r8R2DH8cwD4x7c/lqRptGIwquoR4GfnWLIH+HINHAPeleS94xpQ0vQYxz2MLcDzI9uLw32SfslsGsMxssy+ZZ83T3KAwWULF1100e9eeeWVY/j2ks7HE0888ZOqmlnN144jGIvAtpHtrcDp5RZW1SHgEMDs7GzNz8+P4dtLOh9J/mO1XzuOS5I54E+Gvy25Dnipqn48huNKmjIrnmEkuR+4Hrg0ySLwN8CvAFTVF4EjwE3AAvAy8GdrNaykyVoxGFW1b4X3C/jE2CaSNLV80lNSm8GQ1GYwJLUZDEltBkNSm8GQ1GYwJLUZDEltBkNSm8GQ1GYwJLUZDEltBkNSm8GQ1GYwJLUZDEltBkNSm8GQ1GYwJLUZDEltBkNSm8GQ1GYwJLUZDEltBkNSm8GQ1GYwJLUZDEltBkNSm8GQ1GYwJLUZDEltBkNSm8GQ1GYwJLUZDEltrWAk2ZXkZJKFJHcs8/5lSR5K8mSSp5PcNP5RJU3aisFIciFwELgR2AnsS7JzybK/Bg5X1dXAXuAfxj2opMnrnGFcCyxU1amqeg14ANizZE0B7xy+vgQ4Pb4RJU2LTjC2AM+PbC8O9436DHBLkkXgCPDJ5Q6U5ECS+STzZ86cWcW4kiapE4wss6+WbO8D7quqrcBNwFeSvOXYVXWoqmaranZmZub8p5U0UZ1gLALbRra38tZLjv3AYYCq+h7wDuDScQwoaXp0gvE4sCPJ9iSbGdzUnFuy5j+BjwAk+QCDYHjNIf2SWTEYVfUGcDtwFHiWwW9Djie5O8nu4bJPA7cl+QFwP3BrVS29bJG0wW3qLKqqIwxuZo7uu2vk9Qngg+MdTdK08UlPSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDU1gpGkl1JTiZZSHLHWdZ8NMmJJMeTfHW8Y0qaBptWWpDkQuAg8AfAIvB4krmqOjGyZgfwV8AHq+rFJO9Zq4ElTU7nDONaYKGqTlXVa8ADwJ4la24DDlbViwBV9cJ4x5Q0DTrB2AI8P7K9ONw36grgiiSPJjmWZNe4BpQ0PVa8JAGyzL5a5jg7gOuBrcB3k1xVVT9/04GSA8ABgMsuu+y8h5U0WZ0zjEVg28j2VuD0Mmu+WVWvV9WPgJMMAvImVXWoqmaranZmZma1M0uakE4wHgd2JNmeZDOwF5hbsuZfgA8DJLmUwSXKqXEOKmnyVgxGVb0B3A4cBZ4FDlfV8SR3J9k9XHYU+GmSE8BDwF9W1U/XamhJk5Gqpbcj1sfs7GzNz89P5HtL/58leaKqZlfztT7pKanNYEhqMxiS2gyGpDaDIanNYEhqMxiS2gyGpDaDIanNYEhqMxiS2gyGpDaDIanNYEhqMxiS2gyGpDaDIanNYEhqMxiS2gyGpDaDIanNYEhqMxiS2gyGpDaDIanNYEhqMxiS2gyGpDaDIanNYEhqMxiS2gyGpDaDIanNYEhqMxiS2gyGpLZWMJLsSnIyyUKSO86x7uYklWR2fCNKmhYrBiPJhcBB4EZgJ7Avyc5l1l0M/AXw2LiHlDQdOmcY1wILVXWqql4DHgD2LLPus8A9wCtjnE/SFOkEYwvw/Mj24nDfLyS5GthWVd8a42ySpkwnGFlmX/3izeQC4PPAp1c8UHIgyXyS+TNnzvSnlDQVOsFYBLaNbG8FTo9sXwxcBTyc5DngOmBuuRufVXWoqmaranZmZmb1U0uaiE4wHgd2JNmeZDOwF5j73zer6qWqurSqLq+qy4FjwO6qml+TiSVNzIrBqKo3gNuBo8CzwOGqOp7k7iS713pASdNjU2dRVR0BjizZd9dZ1l7/9seSNI180lNSm8GQ1GYwJLUZDEltBkNSm8GQ1GYwJLUZDEltBkNSm8GQ1GYwJLUZDEltBkNSm8GQ1GYwJLUZDEltBkNSm8GQ1GYwJLUZDEltBkNSm8GQ1GYwJLUZDEltBkNSm8GQ1GYwJLUZDEltBkNSm8GQ1GYwJLUZDEltBkNSm8GQ1GYwJLUZDEltrWAk2ZXkZJKFJHcs8/6nkpxI8nSS7yR53/hHlTRpKwYjyYXAQeBGYCewL8nOJcueBGar6neAbwD3jHtQSZPXOcO4FlioqlNV9RrwALBndEFVPVRVLw83jwFbxzumpGnQCcYW4PmR7cXhvrPZDzy43BtJDiSZTzJ/5syZ/pSSpkInGFlmXy27MLkFmAU+t9z7VXWoqmaranZmZqY/paSpsKmxZhHYNrK9FTi9dFGSG4A7gQ9V1avjGU/SNOmcYTwO7EiyPclmYC8wN7ogydXAPwG7q+qF8Y8paRqsGIyqegO4HTgKPAscrqrjSe5Osnu47HPArwNfT/JUkrmzHE7SBta5JKGqjgBHluy7a+T1DWOeS9IU8klPSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDUZjAktRkMSW0GQ1KbwZDU1gpGkl1JTiZZSHLHMu//apKvDd9/LMnl4x5U0uStGIwkFwIHgRuBncC+JDuXLNsPvFhVvwl8HvjbcQ8qafI6ZxjXAgtVdaqqXgMeAPYsWbMH+NLw9TeAjyTJ+MaUNA06wdgCPD+yvTjct+yaqnoDeAl49zgGlDQ9NjXWLHemUKtYQ5IDwIHh5qtJnml8/2lyKfCTSQ9xHjbavODM6+G3VvuFnWAsAttGtrcCp8+yZjHJJuAS4GdLD1RVh4BDAEnmq2p2NUNPykabeaPNC868HpLMr/ZrO5ckjwM7kmxPshnYC8wtWTMH/Onw9c3Av1bVW84wJG1sK55hVNUbSW4HjgIXAvdW1fEkdwPzVTUH/DPwlSQLDM4s9q7l0JImo3NJQlUdAY4s2XfXyOtXgD8+z+996DzXT4ONNvNGmxeceT2set545SCpy0fDJbWteTA22mPljXk/leREkqeTfCfJ+yYx55KZzjnzyLqbk1SSid/R78yc5KPDz/p4kq+u94xLZlnp5+KyJA8leXL4s3HTJOYcmefeJC+c7dGFDHxh+N/zdJJrWgeuqjX7w+Am6b8D7wc2Az8Adi5Z8+fAF4ev9wJfW8uZxjDvh4FfG77++CTn7c48XHcx8AhwDJid9pmBHcCTwG8Mt98z5fMeAj4+fL0TeG7Cn/HvA9cAz5zl/ZuABxk8Q3Ud8FjnuGt9hrHRHitfcd6qeqiqXh5uHmPwXMokdT5jgM8C9wCvrOdwZ9GZ+TbgYFW9CFBVL6zzjKM68xbwzuHrS3jrs0rrqqoeYZlnoUbsAb5cA8eAdyV570rHXetgbLTHyjvzjtrPoNKTtOLMSa4GtlXVt9ZzsHPofM5XAFckeTTJsSS71m26t+rM+xngliSLDH6j+Mn1GW3VzvdnHWj+WvVtGNtj5eukPUuSW4BZ4ENrOtHKzjlzkgsY/AviW9droIbO57yJwWXJ9QzO4r6b5Kqq+vkaz7aczrz7gPuq6u+S/B6D55Kuqqr/XvvxVmVVf+/W+gzjfB4r51yPla+TzrwkuQG4E9hdVa+u02xns9LMFwNXAQ8neY7B9erchG98dn8uvllVr1fVj4CTDAIyCZ159wOHAarqe8A7GPwbk2nV+ll/izW+8bIJOAVs5/9uFv32kjWf4M03PQ9P8EZRZ96rGdwA2zGpOc935iXrH2byNz07n/Mu4EvD15cyOH1+9xTP+yBw6/D1B4Z/+TLhz/lyzn7T8494803P77eOuQ5D3wT82/Av2Z3DfXcz+L8zDEr8dWAB+D7w/gl/yCvN+23gv4Cnhn/mJjlvZ+YlaycejObnHODvgRPAD4G9Uz7vTuDRYUyeAv5wwvPeD/wYeJ3B2cR+4GPAx0Y+34PD/54fdn8mfNJTUptPekpqMxiS2gyGpDaDIanNYEhqMxiS2gyGpDaDIantfwCDxqEiBvYPYAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray() # Queremos las imágenes en grises\n",
    "plt.matshow(ok) # Imprimir una imagen dada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_raw = tf.io.read_file(\"output/fig1.png\")\n",
    "    \n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    test_feed_dict = {\n",
    "        x : mnist.test.images,\n",
    "        y : mnist.test.labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Do not use tf.reset_default_graph() to clear nested graphs. If you need a cleared graph, exit the nesting and create a new graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6dd30ebbafa3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m# mnist data image of shape 28*28=784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m784\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# 0-9 digits recognition => 10 classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mreset_default_graph\u001b[1;34m()\u001b[0m\n\u001b[0;32m   5586\u001b[0m   \"\"\"\n\u001b[0;32m   5587\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_default_graph_stack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_cleared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5588\u001b[1;33m     raise AssertionError(\"Do not use tf.reset_default_graph() to clear \"\n\u001b[0m\u001b[0;32m   5589\u001b[0m                          \u001b[1;34m\"nested graphs. If you need a cleared graph, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5590\u001b[0m                          \"exit the nesting and create a new graph.\")\n",
      "\u001b[1;31mAssertionError\u001b[0m: Do not use tf.reset_default_graph() to clear nested graphs. If you need a cleared graph, exit the nesting and create a new graph."
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    tf.ex\n",
    "    tf.reset_default_graph()\n",
    "    # mnist data image of shape 28*28=784\n",
    "    x = tf.placeholder(tf.float32, [None, 784])    \n",
    "    # 0-9 digits recognition => 10 classes\n",
    "    y = tf.placeholder(tf.float32, [None, 10])    \n",
    "    output = inference(x) \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "        print(\"Model restored\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "+ [1] Huang, L., Joseph, A. D., Nelson, B., Rubinstein, B. I., & Tygar, J. D. (2011, October). Adversarial machine learning. In Proceedings of the 4th ACM workshop on Security and artificial intelligence (pp. 43-58). ACM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
