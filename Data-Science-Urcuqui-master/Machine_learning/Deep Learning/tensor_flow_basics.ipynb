{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones Basicas de TensorFlow\n",
    "\n",
    "## Introduccion\n",
    "\n",
    "TensorFlow propone un modelo computacional distinto al normalmente usado: la computacion simbolica. Mas adelante veremos que significa esto, pero por ahora solo veamos un ejemplo de una computacion en python estadar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 1.0  #parametro\n",
    "b = 2.0  #parametro\n",
    "\n",
    "def f(x):  # x es un input\n",
    "    return w * x + b\n",
    "\n",
    "f(1) # w * x + b == 1.0 * 1.0 + 2.0 == 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui diremos que `f` es una funcion de `x` que esta parametrizada por las variables `w` y `b`. Esto lo podriamos escribir matematicamente de la siguiente forma:\n",
    "\n",
    "# $f(x; w,b) = w x + b$\n",
    "\n",
    "Esto quiere decir que si bien `w` y `b` no son parte de los argumentos de `f`, si determinan su comportamiento. Si cambiamos `w` o `b` tambien cambiara el valor de `f` dado cierto `x`. Modifiquemos `b` a `10.0` a ver que sucede:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 10.0\n",
    "\n",
    "f(1) # w * x + b == 1.0 * 1.0 + 10.0 == 11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es de esperarse, el valor de `f` cambio. Durante el resto del notebook veremos lo necesario para recrear esto en TensorFlow\n",
    "\n",
    "## Import\n",
    "\n",
    "Por convension se importa `tensorflow` como `tf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensores\n",
    "Un tensor es un arreglo multidimensional. Por ejemplo los vectores son tensores de `1` dimension, las matrices son tensores de dimension `2`, y los escalares son tensores de `0` dimensiones. Asi mismo podemos crear tensores de mayores dimensiones, por ejemplo, las imagenes se pueden representar como un tensor de dimension "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n",
    "El tensor mas simple de TensorFlow es un tensor constante. Para crear uno utilizamos `tf.constant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.constant(5.0)\n",
    "\n",
    "print c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, como vemos en la evaluacion de la celda anterior, este tensor constante `c` no parece indicarnos el valor que contiene, para extraer el valor primero tenemos crear crear una session y correr el tensor en ella:\n",
    "\n",
    "## Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando `run` pudimos recuperar el valor de `c`! Sin embargo es no parece muy utilil pare ahora. Sin embargo, veamos como crear operaciones un poco mas complejas. Al igual que en numpy, los tensores sobreescriben la mayoria de los operadores de python y nos permiten crear nuevos tensores de esta manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = c * 12.0\n",
    "\n",
    "print k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui creamos `k` a partir de `c` y el numero `12.0`. Lo interesante es que el `print` nos da una pista de que `k` es un tensor de tipo \"mul\", esto se debe a que representa la operacion de multiplicacion. Para recuperar el valor de `k` debemos ejecutarlo en la session denuevo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholder\n",
    "Hasta ahora solo hemos creado expresiones constantes y esto no es tan util. Para introducir entradas del exterior a las expresiones debemos crear un tensor tipo `placeholder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, ())\n",
    "y = x * 2.0\n",
    "\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, definimos un tensor sin ningun valor y creamos un operacion a partir de el, ¿pero que pasara si lo evaluamos en la session?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sess.run(y)\n",
    "except:\n",
    "    print \"Error!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos obtenemos un error, esto es porque tensorflow necesita que definamos un valor para `x` dentro del grafo para poder calcular el valor de `y`. Esto lo hacemos pasando un diccionario de tensores a valores al parametro `feed_dict` de `run`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores = {x:  9.0}\n",
    "\n",
    "print float(sess.run(y, valores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable\n",
    "Hemos creados expresiones \"puras\" en el sentido que dados los mismo valores para los `placeholders` siempre data los mismo valores para el resto de los tensores, en otras palabras, no hay estado. Para tener sistemas que guarden estado utilizamos `Variable`. Creemos una variable sensilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.Variable(1.0)\n",
    "print a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui creamos una variable con un valor inicial de `1.0`, sin embargo las variables son un poco diferentes al resto de los tensores en el sentido que deben ser inicializadas, esto posiblemente es para reservar memoria en el dispositivo que vaya a almacenar esta variable, si no lo hacemos e intentamos evaluar una expresion tendremos errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print sess.run(a)\n",
    "except:\n",
    "    print \"Error!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para iniciar las variables corremos `tf.global_variables_initializer()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta operacion no retorna nada pero como efecto secundario inicia las variables. Ahora si corremos `a` podemos obtener su valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como dijimos el proposito de tener variables es poder almacener y lo mas importante actualizar cierto estado, de otra manera parecen constantes. Por lo tanto vamos a definir la operacion\n",
    "\n",
    "$a := a * 2.0$\n",
    "\n",
    "en TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update = a.assign(a * 2.0) #a = a * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora si corremos `a` veremos que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...sigue igual. Esto es porque debemos correr el tensor `update` para que `a` se actualice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(update)\n",
    "\n",
    "print sess.run(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfecto! Si volvemos a correr la celda anterior varias veces veremos que `a` se va duplicando cada vez. \n",
    "\n",
    "## Uniendo Todo\n",
    "Ahora estamos preparados para recrear nuestra funcion `f` original en tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(1.0) #parametro\n",
    "b = tf.Variable(2.0) #parametro\n",
    "\n",
    "x = tf.placeholder(tf.float32, []) #input\n",
    "\n",
    "f = w * x + b  # f(x; w, b)\n",
    "\n",
    "#iniciar variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# f(1.0)\n",
    "sess.run(f, feed_dict={x: 1.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genial! Reproducimos el resultado original de python. Ahora nos falta modificar `b` a `10.0` como lo hicimos en anteriormente y ver como cambia `f`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = 10.0\n",
    "sess.run(tf.assign(b, 10.0))\n",
    "\n",
    "# f(1.0)\n",
    "sess.run(f, feed_dict={x: 1.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Que sigue?\n",
    "\n",
    "Todo esto realmente parece una forma muy complicada de realizar oparaciones que serian mas facil con python o numpy. Las ventajas de TensorFlow para el Deep Learning y la computacion cientifica en general son las siguientes:\n",
    "\n",
    "* Cada tensor puede estar ubicado en un dispositivo diferente como una gpu, la cpu normal, o una maquina remota. Esto es importante para correr grandes modelos utilizando paralelismo y computacion distribuida.\n",
    "* La computacion simbolica le permite a tensorflow calcular derivadas de una expresion con respecto a una subexpresion de la misma, esto es importante para calcular el gradiente de las redes neuronales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gradients\n",
    "Gracias a la computacion simbolica, es decir, que no se ejecuta operacion para generar valores de forma inmediata sino que se guarda un grafo de la expresion, muy parecido a una formula matematica, TensorFlow puede calcular la derivada de una expresion con respecto a una subexpresion de la misma. Esto es muy importante para el algoritmo `Gradient Descent` que depende totalmente de poder calcular el gradiente del error con respecto a los pesos:\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "    \\Delta = \\nabla_{\\theta} E(x, y; \\theta)\n",
    "\\end{equation}\n",
    "$\n",
    "<br>\n",
    "$\n",
    "\\begin{equation}\n",
    "    \\theta := \\theta - \\alpha \\Delta\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "A continuacion vamos a calcular la derivada de $f$ con respecto a $w$ utilizando la funcion `gradients`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfdw = tf.gradients(f, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analiticamente el valor de esta operacion es\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "    \\frac{\\delta f}{\\delta w} = \\frac{\\delta (x w + b)}{\\delta w} = x\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "y lo podemos comprobar numericamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = sess.run(dfdw, feed_dict={x: 10.0})\n",
    "x_val = sess.run(x, feed_dict={x: 10.0})\n",
    "\n",
    "print \"Gradiente: {0}, x: {1}\".format(grad[0], x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, ambdas expresiones tienen el mismo valor!\n",
    "\n",
    "## Gradient Descent\n",
    "Ahora vamos aplicar todo el algoritmo de que involucra los siguientes pasos:\n",
    "\n",
    "<img src=\"images/gradient-descent.png\" height=\"42\">\n",
    "\n",
    "Primero vamos a importar unas librarias y generar algunos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "from plotly import graph_objs as go\n",
    "import numpy as np\n",
    "py.init_notebook_mode()\n",
    "\n",
    "n = 50\n",
    "\n",
    "x_data = np.random.uniform(low=0.0, high=100.0, size=(n, 1))\n",
    "y_data = 3.5 * x_data + 40.3 + np.random.normal(loc=0.0, scale=25.0, size=(n, 1))\n",
    "\n",
    "#normalizar data\n",
    "x_data = (x_data - np.mean(x_data)) / np.average(x_data)\n",
    "y_data = (y_data - np.mean(y_data)) / np.average(y_data)\n",
    "\n",
    "scatter = go.Scatter(\n",
    "    x=x_data[:, 0], \n",
    "    y=y_data[:, 0], \n",
    "    mode = 'markers', \n",
    "    marker = dict(size = 10),\n",
    "    name=\"data\"\n",
    ")\n",
    "\n",
    "layout = go.Layout(xaxis=dict(title='x'), yaxis=dict(title='y'))\n",
    "\n",
    "\n",
    "py.iplot(go.Figure(data=[scatter], layout=layout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a crear un modelo con parametros aleatorios y visualizarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Tarea: Crear los tensores\n",
    "####################\n",
    "\n",
    "x = \n",
    "y = \n",
    "\n",
    "w = \n",
    "b = \n",
    "\n",
    "h = \n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "x_model = [np.min(x_data), np.max(x_data)]\n",
    "y_model = sess.run(h, feed_dict={x: x_model})\n",
    "\n",
    "\n",
    "model_line = go.Scatter(\n",
    "    x=x_model, \n",
    "    y=y_model,\n",
    "    name=\"model\"\n",
    ")\n",
    "\n",
    "py.iplot(go.Figure(data=[scatter, model_line], layout=layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alfa = 0.5\n",
    "\n",
    "#calcular error\n",
    "E = \n",
    "\n",
    "#calcular gradiente\n",
    "dEdw, dEdb = \n",
    "\n",
    "#actualizar pesos\n",
    "update_w, update_b = \n",
    "\n",
    "#realizar operacion 200 veces\n",
    "for i in range(200):\n",
    "    #update\n",
    "\n",
    "#visualizar modelo aprendido\n",
    "y_model = sess.run(h, feed_dict={x: x_model})\n",
    "\n",
    "model_line = go.Scatter(\n",
    "    x=x_model, \n",
    "    y=y_model,\n",
    "    name=\"model\"\n",
    ")\n",
    "\n",
    "py.iplot(go.Figure(data=[scatter, model_line], layout=layout))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}